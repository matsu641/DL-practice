{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matsu641/DL-practice/blob/main/lecture07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NWVFkhv-EW2"
      },
      "source": [
        "# 第7回講義 演習\n",
        "\n",
        "本演習ではPyTorchを使用し，基本的な回帰結合型ニューラルネット(RNN)と，その一種である長短期記憶(LSTM)を実装し，文章の分類タスクを解いていきます．\n",
        "\n",
        "[IMDb (Internet Movie Database)](https://huggingface.co/datasets/stanfordnlp/imdb) と呼ばれるデータセットには，映画のレビュー文とその評価についてpositiveかnegativeか記録されています．\n",
        "\n",
        "<div style=\"text-align: center;\">【データセットのイメージ】</div>\n",
        "\n",
        "| レビュー | 評価 |\n",
        "|:--------:|:-------------:|\n",
        "|Where's Michael Caine when you need him? I've ...|0|\n",
        "|To experience Head you really need to understa...|1|\n",
        "\n",
        "0 = negative, 1 = positive\n",
        "\n",
        "そこで各レビュー文を入力として，その評価positive/negativeの二値分類をRNNで行ってみましょう．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-aoVICDcH2W"
      },
      "source": [
        "## 目次\n",
        "\n",
        " [【課題】RNNと派生モデルの実装と学習](#scrollTo=kwLF7moq_PCZ&line=1&uniqifier=1)\n",
        "1. [データセットの読み込み](#scrollTo=zEltPNkLuLz6)\n",
        "2. [訓練実行(trainer)関数の定義](#scrollTo=G-laa4YqQRji)\n",
        "1. Recurrent Neural Network (RNN) によるIMDbのsentiment analysis\n",
        "\n",
        " 3.1. [Embedding層](#scrollTo=Urh6GUOQKBzE)  \n",
        "\n",
        " 3.2. [RNN](#scrollTo=ZNPaK9ExKBzI)  \n",
        "\n",
        " 3.3. [分類器](#scrollTo=2O0bZWqVOVk0)\n",
        "\n",
        " 3.4. [学習](#scrollTo=emiO4f5rCklA)\n",
        "\n",
        " 3.5. [torch.nn.RNN, torch.nn.Embeddingを用いたネットワークの記述](#scrollTo=yCktWJ9N8QDN)\n",
        "\n",
        "1. Long short-term memory (LSTM) によるIMDbのsentiment analysis\n",
        "\n",
        " 4.1. [LSTM](#scrollTo=tsXtYkNEm1Bh)\n",
        "\n",
        " 4.2. [分類器](#scrollTo=IfHaLvJJWHeI)\n",
        "\n",
        " 4.3. [学習](#scrollTo=qR2iKUy7yA3R)\n",
        "\n",
        " 4.4. [torch.nn.LSTMを用いたネットワークの記述](#scrollTo=thf8W0lywagD)\n",
        "\n",
        "5. Bidirectional LSTM\n",
        "\n",
        " 5.1. [BidirectionalLSTM](#scrollTo=L9ZNn5gTP2yH)\n",
        "\n",
        " 5.2. [学習](#scrollTo=1xbAI25fQA2E)\n",
        "\n",
        "1. 【補足】[Gradient Clippingによる長系列への対処](#scrollTo=ExuiSiTo2k3m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AP7Iwy3PFZ3m"
      },
      "outputs": [],
      "source": [
        "!pip install portalocker\n",
        "!pip install datasets\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import f1_score\n",
        "from datasets import load_dataset\n",
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwLF7moq_PCZ"
      },
      "source": [
        "## 【課題】RNNと派生モデルの実装と学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEltPNkLuLz6"
      },
      "source": [
        "## 1.データセットの読み込み\n",
        "\n",
        "自然言語処理において，データとなる文をそのままネットワークに入力することは出来ないので，適切な前処理をする必要があります．\n",
        "\n",
        "前処理の手順（英文の場合）は大まかに，\n",
        "- 単語ごとに区切る\n",
        "- 各単語にIDを割り振る\n",
        "\n",
        "という手順で行われ，この手順を経ることで，元々の文は整数列に変換され，ネットワークに入力することが可能となります．\n",
        "\n",
        "また，本演習では各単語にIDを割り振る処理に`NLTK`と呼ばれるライブラリを用いています．詳しく知りたい方は，[公式ドキュメント](https://www.nltk.org/api/nltk.html)を参照してください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2xVBypuxc-M"
      },
      "outputs": [],
      "source": [
        "# torch.log(0)によるnanを防ぐための関数\n",
        "def torch_log(x):\n",
        "    return torch.log(torch.clamp(x, min=1e-10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9oN38u4fwNju"
      },
      "outputs": [],
      "source": [
        "# IMDBデータセットのダウンロード\n",
        "# トークンを要求された場合でも、データセットのダウンロードにはHFトークンは不要なため、キャンセルをクリック\n",
        "print(\"Loading IMDB dataset...\")\n",
        "dataset = load_dataset(\"stanfordnlp/imdb\")\n",
        "# データの分割\n",
        "train_data, valid_data = random_split(\n",
        "    dataset['train'], [20000, 5000],\n",
        "    )\n",
        "test_data = dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeotUWUJx9_-"
      },
      "source": [
        "[nltk.probability.FreqDist](https://www.nltk.org/api/nltk.probability.html#nltk.probability.FreqDist)で訓練データの文章内の単語を数え上げ，語彙リスト（`FreqDist`オブジェクト）を作っていきます．\n",
        "\n",
        "引数`specials`で特別なトークンを指定しています．\n",
        "- `<unk>`: Unknown. 出てくる頻度が少なすぎる単語などを未分類としておきます．\n",
        "- `<PAD>`: 短い文章はこのトークンで埋めることで，長い文章に長さを合わせます．\n",
        "- `<BOS>`: Begin of sentence.\n",
        "- `<EOS>`: End of sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_Wl5lKUwNju"
      },
      "outputs": [],
      "source": [
        "# 単語をスペースで区切り，!\"#$%&といった記号を除去する，すべて小文字化する，などの処理\n",
        "def tokenize(text):\n",
        "    # 1. 小文字化\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. 記号を除去 (string.punctuation)\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "    # 3. トークン化 (単語ごとに分割)\n",
        "    tokens = text.split()\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wTwwv3qJxrXG"
      },
      "outputs": [],
      "source": [
        "# 単語の頻度を記録するためのFreqDistオブジェクトを作成\n",
        "counter = FreqDist()\n",
        "for i in range(len(train_data)):\n",
        "    processed = tokenize(train_data[i][\"text\"])\n",
        "    # トークン化した単語リストをFreqDistに追加して頻度を更新\n",
        "    counter.update(processed)\n",
        "\n",
        "print(f\"単語数: {len(counter)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtZDWtT4FYBh"
      },
      "outputs": [],
      "source": [
        "# <unk>をデフォルトに設定し，min_freq回以上出てこない単語は<unk>にする\n",
        "# min_freqとspecialsの適用\n",
        "min_freq = 25\n",
        "specials = ['<unk>', '<PAD>', '<BOS>', '<EOS>']\n",
        "\n",
        "vocab = specials + [word for word, freq in counter.items() if freq >= min_freq]\n",
        "vocab_dict = {word: i for i, word in enumerate(vocab)}\n",
        "word_num = len(vocab_dict)\n",
        "\n",
        "print(f\"単語種数: {word_num}\")\n",
        "print(list(vocab_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eXWV-W9fsJ2"
      },
      "source": [
        "`text_transform()`を`collate_batch()`から呼び，単語のリストを辞書内インデックスのリストに変換します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waztS-jcwNjv"
      },
      "outputs": [],
      "source": [
        "def text_transform(_text, max_length=256):\n",
        "    # tokenがvocab_dictに無い場合、0=<unk>を代入, <BOS>と<EOS>の分 -2\n",
        "    text = [vocab_dict.get(token, 0) for token in tokenize(_text)][:max_length - 2]\n",
        "    text = [vocab_dict['<BOS>']] + text + [vocab_dict['<EOS>']]\n",
        "    return text, len(text)\n",
        "\n",
        "def collate_batch(batch):\n",
        "   label_list, text_list, len_seq_list = [], [], []\n",
        "\n",
        "   for data_point  in list(batch):\n",
        "      _text = data_point.get('text')\n",
        "      _label = data_point.get('label')\n",
        "      label_list.append(_label)\n",
        "\n",
        "      processed_text, len_seq = text_transform(_text)\n",
        "      text_list.append(torch.tensor(processed_text))\n",
        "      len_seq_list.append(len_seq)\n",
        "\n",
        "   return torch.tensor(label_list), pad_sequence(text_list, padding_value=1).T, torch.tensor(len_seq_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4wrvRPx_k4H"
      },
      "source": [
        "上で定義した`collate_batch()`を`DataLoader`に渡すことで，バッチに対してその処理を適用することができます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zNihuaPSuNl"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "   list(train_data),\n",
        "   batch_size=batch_size,\n",
        "   shuffle=True,\n",
        "   collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "   list(valid_data),\n",
        "   batch_size=batch_size,\n",
        "   shuffle=False,\n",
        "   collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-laa4YqQRji"
      },
      "source": [
        "## 2.訓練実行(trainer)関数の定義\n",
        "\n",
        "以降定義するすべてのモデルについて訓練ループは同じなので，ここで関数として実装してしまいます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmcVzxAvQbdJ"
      },
      "outputs": [],
      "source": [
        "# NOTE: dataloaderはグローバルスコープ\n",
        "def train(net, optimizer, n_epochs,):\n",
        "    for epoch in range(n_epochs):\n",
        "        losses_train = []\n",
        "        losses_valid = []\n",
        "\n",
        "        net.train()\n",
        "        n_train = 0\n",
        "        acc_train = 0\n",
        "        for label, line, len_seq in train_dataloader:\n",
        "            net.zero_grad()  # 勾配の初期化\n",
        "\n",
        "            t = label.to(device) # テンソルをGPUに移動\n",
        "            x = line.to(device) # ( batch, time )\n",
        "            len_seq.to(device)\n",
        "\n",
        "            h = net(x, torch.max(len_seq), len_seq)\n",
        "            y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "            loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))  # WRITE ME\n",
        "\n",
        "            loss.backward()  # 誤差の逆伝播\n",
        "\n",
        "            optimizer.step()  # パラメータの更新\n",
        "\n",
        "            losses_train.append(loss.tolist())\n",
        "\n",
        "            n_train += t.size()[0]\n",
        "\n",
        "        # Valid\n",
        "        t_valid = []\n",
        "        y_pred = []\n",
        "        net.eval()\n",
        "        for label, line, len_seq in valid_dataloader:\n",
        "\n",
        "            t = label.to(device) # テンソルをGPUに移動\n",
        "            x = line.to(device)\n",
        "            len_seq.to(device)\n",
        "\n",
        "            h = net(x, torch.max(len_seq), len_seq)\n",
        "            y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "            loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))  # WRITE ME\n",
        "\n",
        "            pred = y.round().squeeze()  # 0.5以上の値を持つ要素を正ラベルと予測する\n",
        "\n",
        "            t_valid.extend(t.tolist())\n",
        "            y_pred.extend(pred.tolist())\n",
        "\n",
        "            losses_valid.append(loss.tolist())\n",
        "\n",
        "        print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}'.format(\n",
        "            epoch,\n",
        "            np.mean(losses_train),\n",
        "            np.mean(losses_valid),\n",
        "            f1_score(t_valid, y_pred, average='macro')\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5oyIOujKBy0"
      },
      "source": [
        "## 3.Recurrent Neural Network (RNN) によるIMDbのsentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urh6GUOQKBzE"
      },
      "source": [
        "### 3.1. Embedding層\n",
        "\n",
        "`Embedding`層では，単語を離散的なidから連続的な数百次元のベクトルに変換(埋め込み; embedding)します．\n",
        "\n",
        "下の`Embedding`クラスにおいて，入力$\\boldsymbol{x}$は各行に文の単語のid列が入った行列で，重み$\\boldsymbol{V}$は各行がそれぞれの単語idのベクトルに対応した行列です．\n",
        "\n",
        "つまりそれぞれの行列のサイズは\n",
        "\n",
        "- $\\boldsymbol{x}$: (ミニバッチサイズ) x (ミニバッチ内の文の最大系列長)\n",
        "- $\\boldsymbol{V}$: (辞書の単語数) x (単語のベクトルの次元数)\n",
        "\n",
        "です．\n",
        "\n",
        "この$\\boldsymbol{V}$から，入力$\\boldsymbol{x}$のそれぞれの単語idに対して対応する単語ベクトルを取り出すことで，各単語をベクトルに変換します．\n",
        "\n",
        "この処理によって出力されるテンソルの次元数は，(ミニバッチサイズ) x (ミニバッチ内の文の最大系列長) x (単語のベクトルの次元数)となります．\n",
        "\n",
        "![embedding](data:image/png;base64,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))\n",
        "\n",
        "$$m:\\text{emb_dim}, \\ n : \\text{vocab_size}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsrziOUkFX07"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.embedding_matrix = nn.Parameter(torch.randn((vocab_size, emb_dim),  # ガウス分布（正規分布）から乱数を生成\n",
        "                                                        dtype=torch.float))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.embedding(x, self.embedding_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNPaK9ExKBzI"
      },
      "source": [
        "### 3.2. RNN\n",
        "\n",
        "RNNクラスでは，Embedding層で各単語がベクトルに変換されたものを入力として処理を行います．ここで入力$\\boldsymbol{x}$は\n",
        "\n",
        "- $\\boldsymbol{x}$: (ミニバッチサイズ) x (ミニバッチ内の文の最大系列長) x (単語のベクトルの次元数)\n",
        "\n",
        "となっています．\n",
        "\n",
        "ここでは `nn.Module` を用いてRNNクラスを定義します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq01kXOFw3hD"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        glorot = 6 / (in_dim + hid_dim*2)\n",
        "        self.W = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "    def function(self, h, x):\n",
        "        return torch.tanh(torch.matmul(torch.cat([h, x], dim=1), self.W) + self.b)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, init_state=None):\n",
        "        x = x.transpose(0, 1)  # 系列のバッチ処理のため、次元の順番を「系列、バッチ」の順に入れ替える\n",
        "        state = init_state\n",
        "\n",
        "        if init_state is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "\n",
        "        size = list(state.unsqueeze(0).size())\n",
        "        size[0] = 0\n",
        "        output = torch.empty(size, dtype=torch.float).to(x.device)  # 一旦空テンソルを定義して順次出力を追加する\n",
        "\n",
        "        if len_seq_max == 0:\n",
        "            len_seq_max = x.size(0)\n",
        "        for i in range(len_seq_max):\n",
        "            state = self.function(state, x[i])\n",
        "            output = torch.cat([output, state.unsqueeze(0)])  # 出力系列の追加\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O0bZWqVOVk0"
      },
      "source": [
        "### 3.3. 分類器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpDGYK_rEcVS"
      },
      "outputs": [],
      "source": [
        "# RNN\n",
        "class SequenceTaggingNet(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(word_num, emb_dim)\n",
        "        self.rnn = RNN(emb_dim, hid_dim)\n",
        "        self.linear = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)  # WRITE ME\n",
        "        h = self.rnn(h, len_seq_max, init_state)\n",
        "        if len_seq is not None:\n",
        "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "        y = self.linear(h)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emiO4f5rCklA"
      },
      "source": [
        "### 3.4. 学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NF1oS8scU160"
      },
      "outputs": [],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 10\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "train(net, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCktWJ9N8QDN"
      },
      "source": [
        "### 3.5. `torch.nn.RNN`, `torch.nn.Embedding` を用いたネットワークの記述\n",
        "\n",
        "`torch.nn.Conv2d`を用いてCNN層を容易に実装することができたように，`torch.nn.RNN`を用いることで容易にRNN層を実装することができます．\n",
        "\n",
        "`torch.nn.RNN`は，系列データ $x$ と初期状態 $h_0$ を引数として受け取り，出力系列 $y$ と最終状態 $h$ を出力します．（`y, h = self.RNN(x, h_0)`）\n",
        "\n",
        "また，少し厄介なことに`nn.RNN`の入力の系列データは，デフォルトで次元が [系列，ミニバッチ，各要素のベクトル] の順番となっています．しかしながら，データローダーが与えるデータは [ミニバッチ，系列，各要素] の順番となっており，この順番の方が直感的であると考えられます．これを解決するため，`torch.nn.RNN`は引数`batch_first`を受け取ることができ，これを`True`にすることで入力系列を [ミニバッチ，系列，各要素] の順番で受け取ることができます．\n",
        "\n",
        "`batch_first=True`とすると出力の順番も入れ替わるので，`transpose`を用いて [系列，ミニバッチ，各要素のベクトル] としてから`len_seq`を元に最終出力を取り出します．\n",
        "\n",
        "さらに，`torch.nn.RNN`は引数`num_layers`を持ち，RNNを何層重ねるかを指定します．多層に重ねることもできますが，ここでは課題2の実装と揃えるため一層とします．\n",
        "\n",
        "また，`torch.nn.Embedding`を用いることでEmbedding層も容易に実装することができます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xou_yoP8Uxrs"
      },
      "outputs": [],
      "source": [
        "# nn.RNN\n",
        "class SequenceTaggingNet2(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(word_num, emb_dim)  # nn.Embeddingの使用\n",
        "        self.rnn = nn.RNN(emb_dim, hid_dim, 1, batch_first=True)  # nn.RNNの使用\n",
        "        self.linear = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)  # WRITE ME\n",
        "        if len_seq_max > 0:\n",
        "            h, _ = self.rnn(h[:, 0:len_seq_max, :], init_state)\n",
        "        else:\n",
        "            h, _ = self.rnn(h, init_state)\n",
        "        h = h.transpose(0, 1)\n",
        "        if len_seq is not None:\n",
        "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "\n",
        "        y = self.linear(h)  # WRITE ME\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlab8ft3U0Fq"
      },
      "outputs": [],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 10\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet2(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "train(net, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzcDxaEvmu_g"
      },
      "source": [
        "## 4.Long short-term memory (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsXtYkNEm1Bh"
      },
      "source": [
        "### 4.1. LSTM\n",
        "\n",
        "実装する式は次のようになります．($\\odot$は要素ごとの積)\n",
        "\n",
        "- 入力ゲート: $\\hspace{20mm}\\boldsymbol{i}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_i \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_i\\right)$\n",
        "- 忘却ゲート: $\\hspace{20mm}\\boldsymbol{f}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_f \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_f\\right)$  \n",
        "- 出力ゲート: $\\hspace{20mm}\\boldsymbol{o}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_o \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_o\\right)$  \n",
        "- セル:　　　 $\\hspace{20mm}\\boldsymbol{c}_t = \\boldsymbol{f}_t \\odot \\boldsymbol{c}_{t-1} + \\boldsymbol{i}_t \\odot \\tanh \\left(\\boldsymbol{W}_c \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_c\\right)$\n",
        "- 隠れ状態: 　$\\hspace{20mm}\\boldsymbol{h}_t = \\boldsymbol{o}_t \\odot \\tanh \\left(\\boldsymbol{c}_t \\right)$\n",
        "\n",
        "単純なRNNでは各ステップの関数の戻り値は隠れ状態のみ ($\\boldsymbol{h}_t$) でしたが，LSTMではセル状態と隠れ状態の2つ ($\\boldsymbol{c}_t, \\boldsymbol{h}_t$) となるので注意してください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Zp__4EDBoJ3"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        glorot = 6/(in_dim + hid_dim*2)\n",
        "\n",
        "        self.W_i = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_i = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_f = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_f = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_o = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_o = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_c = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_c = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "    def function(self, state_c, state_h, x):\n",
        "        i = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_i) + self.b_i)  # WRITE ME\n",
        "        f = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_f) + self.b_f)  # WRITE ME\n",
        "        o = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_o) + self.b_o)  # WRITE ME\n",
        "        c = f*state_c + i*torch.tanh(torch.matmul(torch.cat([state_h, x], dim=1), self.W_c) + self.b_c)  # WRITE ME\n",
        "        h = o*torch.tanh(c)  # WRITE ME\n",
        "        return c, h\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, init_state_c=None, init_state_h=None):\n",
        "        x = x.transpose(0, 1)  # 系列のバッチ処理のため、次元の順番を「系列、バッチ」の順に入れ替える\n",
        "        state_c = init_state_c\n",
        "        state_h = init_state_h\n",
        "        if init_state_c is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_c = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "        if init_state_h is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_h = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "\n",
        "        size = list(state_h.unsqueeze(0).size())\n",
        "        size[0] = 0\n",
        "        output = torch.empty(size, dtype=torch.float).to(x.device)  # 一旦空テンソルを定義して順次出力を追加する\n",
        "\n",
        "        if len_seq_max == 0:\n",
        "            len_seq_max = x.size(0)\n",
        "        for i in range(len_seq_max):\n",
        "            state_c, state_h = self.function(state_c, state_h, x[i])\n",
        "            output = torch.cat([output, state_h.unsqueeze(0)])  # 出力系列の追加\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfHaLvJJWHeI"
      },
      "source": [
        "### 4.2. 分類器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU-z8OtZu_cO"
      },
      "outputs": [],
      "source": [
        "# LSTM\n",
        "class SequenceTaggingNet3(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(word_num, emb_dim)\n",
        "        self.lstm = LSTM(emb_dim, hid_dim)\n",
        "        self.linear = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)  # WRITE ME\n",
        "        h = self.lstm(h, len_seq_max, init_state)  # WRITE ME\n",
        "        if len_seq is not None:\n",
        "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "\n",
        "        y = self.linear(h)  # WRITE ME\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR2iKUy7yA3R"
      },
      "source": [
        "### 4.3. 学習\n",
        "\n",
        "同じタスクを用いてRNNとLSTMの性能を比較します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAyD__D8vLvi"
      },
      "outputs": [],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 5\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet3(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "train(net, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thf8W0lywagD"
      },
      "source": [
        "### 4.4. `nn.LSTM`を用いたネットワークの記述\n",
        "\n",
        "LSTMもRNNと同様に`nn.LSTM`を用いて実装することができます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXqI364xviGx"
      },
      "outputs": [],
      "source": [
        "# nn.LSTM\n",
        "class SequenceTaggingNet4(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(word_num, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, 1, batch_first=True)  # nn.LSTMの使用\n",
        "        self.linear = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)\n",
        "        if len_seq_max > 0:\n",
        "            h, _ = self.lstm(h[:, 0:len_seq_max, :], init_state)\n",
        "        else:\n",
        "            h, _ = self.lstm(h, init_state)\n",
        "        h = h.transpose(0, 1)\n",
        "        if len_seq is not None:\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "        y = self.linear(h)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6D8KzZcw0pv"
      },
      "outputs": [],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 10\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet4(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "train(net, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj0XA0PQP0gG"
      },
      "source": [
        "## 5.双方向LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9ZNn5gTP2yH"
      },
      "source": [
        "### 5.1. BidirectionalLSTM\n",
        "\n",
        "双方向LSTMでは，順方向にシークエンスを処理するLSTM（`self.forward_lstm`）と逆方向にシークエンスを処理するLSTM（`self.backward_lstm`）を別々に用意し，それぞれの出力を結合したものを全結合層へ渡します．  \n",
        "これによりパラメータ数は増えますが，未来方向からの文脈も考慮した予測を行うことができるようになります．\n",
        "\n",
        "[nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)において`bidirectional=True`とするだけで実現できますが，ここではその処理を理解するために実装を行います．\n",
        "\n",
        "- ここではこれまで`SequenceTaggingNet`として実装してきた分類器も含めて`BidirectionalLSTM`クラスとしています．（実装上どちらでも構いません）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XefPHJEyP5vY"
      },
      "outputs": [],
      "source": [
        "class BidirectionalLSTM(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        # 順方向と逆方向のLSTMを用意する\n",
        "        self.emb = nn.Embedding(word_num, emb_dim)\n",
        "        self.forward_lstm = nn.LSTM(emb_dim, hid_dim, 1, batch_first=True)\n",
        "        self.backward_lstm = nn.LSTM(emb_dim, hid_dim, 1, batch_first=True)\n",
        "        self.linear = nn.Linear(hid_dim*2, 1)  # ForwardとBackwardの出力をconcatしたものを渡すので2倍\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)  # (batch_size, seq_length, emb_dim)\n",
        "\n",
        "        # Backwardにはシークエンスを反転して渡す\n",
        "        if len_seq_max > 0:\n",
        "            h1, _ = self.forward_lstm(h[:, 0:len_seq_max, :], init_state)\n",
        "            h2, _ = self.backward_lstm(torch.flip(h[:, 0:len_seq_max, :], dims=[1]), init_state)\n",
        "        else:\n",
        "            h1, _ = self.forward_lstm(h, init_state)  # (batch_size, seq_length, hid_dim)\n",
        "            h2, _ = self.backward_lstm(torch.flip(h, dims=[1]), init_state)  # (batch_size, seq_length, hid_dim)\n",
        "        # Backwardから返ってきたものを再び反転する\n",
        "        h2 = torch.flip(h2, dims=[1])\n",
        "\n",
        "        # ForwardとBackwardの出力を結合\n",
        "        h = torch.cat([h1, h2], dim=2).transpose(0, 1)\n",
        "\n",
        "        if len_seq is not None:\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "\n",
        "        y = self.linear(h)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xbAI25fQA2E"
      },
      "source": [
        "### 5.2. 学習\n",
        "\n",
        "Bidirectional LSTMでも同じタスクを行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UJx334FQBbK"
      },
      "outputs": [],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 10\n",
        "device = 'cuda'\n",
        "\n",
        "net = BidirectionalLSTM(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "train(net, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExuiSiTo2k3m"
      },
      "source": [
        "## 6.【補足】Gradient Clippingによる長系列への対処\n",
        "\n",
        "LSTMは長系列に対しても学習がうまく行きやすいモデルでしたが，一般のRNNにおける長系列の学習の工夫として，**Gradient Clipping**に触れておきます．\n",
        "\n",
        "RNNでは誤差逆伝播法が特に**Back Propagation Through Time (BPTT)**と呼ばれるものになり，各層のみならず各時点の勾配が乗算されます．\n",
        "\n",
        "そのため，通常よりも勾配が過大（或いは過小）になりやすいという特徴をもっています．\n",
        "\n",
        "こうした現象を**勾配爆発（消失）**と呼びますが，勾配爆発は学習を不安定化し収束を困難にします．\n",
        "\n",
        "![Clipping](../figures/Clipping.png)\n",
        "出典：Ian Goodfellow et. al, “Deep Learning”, MIT press, 2016 (http://www.deeplearningbook.org/)\n",
        "\n",
        "そこで，勾配の大きさを意図的に制限して対処しようというのが，Gradient Clippingと呼ばれる手法です．\n",
        "\n",
        "以下のように，`torch.nn.utils.clip_grad_norm_(parameters, max_norm)`を用いることで勾配をclippingすることができます．\n",
        "\n",
        "この関数はparametersにmodelのパラメータ，max_normに勾配の絶対値の最大値を取ることで用いることができます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lpu3TlsbxAuK"
      },
      "outputs": [],
      "source": [
        "def train_gradient_clipping(net, optimizer, n_epochs,\n",
        "):\n",
        "    for epoch in range(n_epochs):\n",
        "        losses_train = []\n",
        "        losses_valid = []\n",
        "\n",
        "        net.train()\n",
        "        n_train = 0\n",
        "        acc_train = 0\n",
        "        for label, line, len_seq in train_dataloader:\n",
        "\n",
        "            net.zero_grad()\n",
        "\n",
        "            t = label.to(device)  # テンソルをGPUに移動\n",
        "            x = line.to(device) # ( batch, time )\n",
        "            len_seq.to(device)\n",
        "\n",
        "            h = net(x, torch.max(len_seq), len_seq)\n",
        "            y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "            loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # 勾配を絶対値1.0でクリッピングする\n",
        "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            losses_train.append(loss.tolist())\n",
        "\n",
        "            n_train += t.size()[0]\n",
        "\n",
        "        t_valid = []\n",
        "        y_pred = []\n",
        "        net.eval()\n",
        "        for label, line, len_seq in valid_dataloader:\n",
        "\n",
        "            t = label.to(device)  # テンソルをGPUに移動\n",
        "            x = line.to(device) # ( batch, time )\n",
        "            len_seq.to(device)\n",
        "\n",
        "            h = net(x, torch.max(len_seq), len_seq)\n",
        "            y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "            loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))\n",
        "\n",
        "            pred = y.round().squeeze()\n",
        "\n",
        "            t_valid.extend(t.tolist())\n",
        "            y_pred.extend(pred.tolist())\n",
        "\n",
        "            losses_valid.append(loss.tolist())\n",
        "\n",
        "        print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}'.format(\n",
        "            epoch,\n",
        "            np.mean(losses_train),\n",
        "            np.mean(losses_valid),\n",
        "            f1_score(t_valid, y_pred, average='macro')\n",
        "        ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MbcEGef5okD"
      },
      "outputs": [],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 10\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet2(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "train_gradient_clipping(net, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWET60FvikgK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "4928584a19934792772f8bb8909943c28c334459e9e815fcc970144b80af4840"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}