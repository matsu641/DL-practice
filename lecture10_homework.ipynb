{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matsu641/DL-practice/blob/main/lecture10_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUU-McVcFGJ0"
      },
      "source": [
        "# 第10回講義 宿題\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 課題\n",
        "自己教師あり学習を用いて事前学習を行い，得られた表現をLinear probingで評価してみましょう．  \n",
        "ネットワークの形などに制限はとくになく，今回のLessonで扱った内容以外の工夫も組み込んでもらって構いません．   \n",
        "\n"
      ],
      "metadata": {
        "id": "O5oAN1R77d0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 目標値\n",
        "なし\n",
        "- 自己教師あり学習の手法によっては計算リソースによって性能が大きく変わるため，目標精度は設定していません．\n",
        "- ただし以下の工夫を行うことで計算リソースが少なくとも，長い学習を分割して行うことができます．  \n",
        "    - model，optimizer, schedulerを一定エポックで保存して，読み込むことで学習を再開することができます．\n",
        "    - 演習のようにschedulerを実装した場合は保存は必要なく，同じ引数でインスタンスを作成して`__call__`の際に与えるepochを学習の続きから与えれば動作します．  \n",
        "    - 参考: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "\n"
      ],
      "metadata": {
        "id": "nTHFJiQT7j2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ルール\n",
        "- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください．\n",
        "- 自己教師あり学習では以下のセルで指定されている`x_train`以外の学習データは用いないでください．\n",
        "- Linear probingの際には`x_train`, `t_train`以外の学習データは用いないでください．\n"
      ],
      "metadata": {
        "id": "8ynk5tNn7wU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 提出方法\n",
        "- 2つのファイルを提出していただきます．\n",
        "    1. テストデータ (`x_test`) に対する予測ラベルを`submission_pred.csv`として保存し，**Omnicampusの宿題タブから「第10回 表現学習と自己教師あり学習」を選択して**提出してください．\n",
        "    2. それに対応するpythonのコードを`submission_code.py`として保存し，**Omnicampusの宿題タブから「第10回 表現学習と自己教師あり学習 (code)」を選択して**提出してください．pythonファイル自体の提出ではなく，「提出内容」の部分にコードをコピー&ペーストしてください．\n",
        "      \n",
        "- なお，採点は1で行い，2はコードの確認用として利用します（成績優秀者はコード内容を公開させていただくかもしれません）．コードの内容を変更した場合は，**1と2の両方を提出し直してください**．"
      ],
      "metadata": {
        "id": "dKK7M3pK7ypa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 評価方法\n",
        "- 予測ラベルの`t_test`に対する精度 (Accuracy) で評価します．\n",
        "- 即時採点しLeader Boardを更新します（採点スケジュールは別アナウンス）．\n",
        "- 締切時の点数を最終的な評価とします．"
      ],
      "metadata": {
        "id": "-uRo31Z171g_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ドライブのマウント"
      ],
      "metadata": {
        "id": "7OGn9I1M8Jzv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQM_SpiDHfso",
        "outputId": "68f6e9db-c492-4aed-ccae-d754c1f8cf3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 作業ディレクトリを指定\n",
        "work_dir = 'drive/MyDrive/Colab Notebooks/DLBasics2025_colab'"
      ],
      "metadata": {
        "id": "l8EkkaqirN6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN8Jq5a8J5HV"
      },
      "source": [
        "### データの読み込み（このセルは修正しないでください）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNpUF5xOJ8bG"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#学習データ\n",
        "x_train = np.load(work_dir + '/Lecture10/data/x_train.npy')\n",
        "t_train = np.load(work_dir + '/Lecture10/data/t_train.npy')\n",
        "\n",
        "#テストデータ\n",
        "x_test = np.load(work_dir + '/Lecture10/data/x_test.npy')\n",
        "\n",
        "class train_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_train, t_train):\n",
        "        data = x_train.astype('float32')\n",
        "        self.x_train = []\n",
        "        for i in range(data.shape[0]):\n",
        "            self.x_train.append(Image.fromarray(np.uint8(data[i])))\n",
        "        self.t_train = t_train\n",
        "        self.transform = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.x_train[idx]), torch.tensor(t_train[idx], dtype=torch.long)\n",
        "\n",
        "class test_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_test):\n",
        "        data = x_test.astype('float32')\n",
        "        self.x_test = []\n",
        "        for i in range(data.shape[0]):\n",
        "            self.x_test.append(Image.fromarray(np.uint8(data[i])))\n",
        "        self.transform = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_test)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.x_test[idx])\n",
        "\n",
        "trainval_data = train_dataset(x_train, t_train)\n",
        "test_data = test_dataset(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSqA6Ni3MDSX"
      },
      "source": [
        "### データローダの準備  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63ODMwChMEy_"
      },
      "outputs": [],
      "source": [
        "val_size = 3000\n",
        "train_data, valid_data = torch.utils.data.random_split(trainval_data, [len(trainval_data) - val_size, val_size])\n",
        "\n",
        "train_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(0.5, 0.5)]\n",
        ")\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(0.5, 0.5)]\n",
        ")\n",
        "\n",
        "trainval_data.transform = train_transform\n",
        "test_data.transform = test_transform\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "dataloader_valid = torch.utils.data.DataLoader(\n",
        "    valid_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQpTXlwbKRdW"
      },
      "source": [
        "### 自己教師あり学習の実装\n",
        "MAEを利用することを想定していますが，他の自己教師あり学習を利用していただいて構いません．   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzlJ4q1uKagF"
      },
      "outputs": [],
      "source": [
        "def fix_seed(seed=1234):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "fix_seed(seed=42)\n",
        "\n",
        "\n",
        "def random_indexes(size):\n",
        "    \"\"\"\n",
        "    パッチをランダムに並べ替えるためのindexを生成する関数．\n",
        "\n",
        "    Argument\n",
        "    --------\n",
        "    size : int\n",
        "        入力されるパッチの数（系列長Nと同じ値）．\n",
        "    \"\"\"\n",
        "    forward_indexes = np.arange(size)  # 0からsizeまでを並べた配列を作成\n",
        "    np.random.shuffle(forward_indexes)  # 生成した配列をシャッフルすることで，パッチの順番をランダムに決定\n",
        "    backward_indexes = np.argsort(forward_indexes)  # 並べ替えたパッチをもとの順番に戻すためのidx\n",
        "\n",
        "    return forward_indexes, backward_indexes\n",
        "\n",
        "\n",
        "def take_indexes(sequences, indexes):\n",
        "    \"\"\"\n",
        "    パッチを並べ替えるための関数．\n",
        "\n",
        "    Argument\n",
        "    --------\n",
        "    sequences : torch.Tensor\n",
        "        入力画像をパッチ分割したデータ．(B, N, dim)の形状をしている．\n",
        "    indexes : np.ndarray\n",
        "        並べ替えるために利用するindex．\n",
        "        random_indexesで生成したforward_indexesかbackward_indexesが入ることが想定されている．\n",
        "    \"\"\"\n",
        "    return torch.gather(sequences, dim=1, index=indexes.unsqueeze(2).repeat(1, 1, sequences.shape[-1]))\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    # WRITE ME\n",
        "\n",
        "\n",
        "class FFN(nn.Module):\n",
        "    # WRITE ME\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    # WRITE ME\n",
        "\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "    # WRITE ME\n",
        "\n",
        "\n",
        "class PatchShuffle(nn.Module):\n",
        "    # WRITE ME\n",
        "\n",
        "\n",
        "class MAE_Encoder(nn.Module):\n",
        "    # WRITE ME\n",
        "\n",
        "\n",
        "class MAE_Decoder(nn.Module):\n",
        "    # WRITE ME\n",
        "\n",
        "\n",
        "class MAE_ViT(nn.Module):\n",
        "    # WRITE ME\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = # WRITE ME\n",
        "epochs = # WRITE ME\n",
        "lr = # WRITE ME\n",
        "batch_size = # WRITE ME\n",
        "optimizer = # WRITE ME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR8uNlkCxo3d"
      },
      "source": [
        "### 事前学習（自己教師あり学習）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfIeOGbbxqXx"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    # WRITE ME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHOBi4auxuPR"
      },
      "source": [
        "### Linear probing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GeuhPBryfQa"
      },
      "outputs": [],
      "source": [
        "val_size = 3000\n",
        "train_data, valid_data = torch.utils.data.random_split(trainval_data, [len(trainval_data) - val_size, val_size])\n",
        "\n",
        "train_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(0.5, 0.5)]\n",
        ")\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(0.5, 0.5)]\n",
        ")\n",
        "\n",
        "trainval_data.transform = train_transform\n",
        "test_data.transform = test_transform\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "dataloader_valid = torch.utils.data.DataLoader(\n",
        "    val_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8n5wVT-xvv1"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    # WRITE ME\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "encoder = # WRITE ME\n",
        "model = # WRITE ME\n",
        "epochs = # WRITE ME\n",
        "lr = # WRITE ME\n",
        "batch_size = # WRITE ME\n",
        "optimizer = # WRITE ME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5T6QiHwyTRj"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    # WRITE ME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72n19Q_RyqWl"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "t_pred = []\n",
        "for x in dataloader_test:\n",
        "    x = x.to(device)\n",
        "    y = model(x)\n",
        "\n",
        "    # モデルの出力を予測値のスカラーに変換\n",
        "    pred = y.argmax(1).tolist()\n",
        "    t_pred.extend(pred)\n",
        "\n",
        "submission = pd.Series(t_pred, name='label')\n",
        "submission.to_csv(work_dir + '/Lecture10/submission_pred.csv', header=True, index_label='id')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}